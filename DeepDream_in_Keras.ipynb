{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepDream in Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0TwNfh653iQ",
        "colab_type": "text"
      },
      "source": [
        "### Implement DeepDream algorithm in Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C7cS4Kw47Wh",
        "colab_type": "code",
        "outputId": "a4d46583-f5c4-4621-b7a1-99a5473ca2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from keras.applications import inception_v3\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import scipy\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#wont be training the model, so disable all training operations\n",
        "K.set_learning_phase(0)\n",
        "\n",
        "#Load the inception v3 network without the convolutional base, weights = pretrained ImageNet weights\n",
        "model = inception_v3.InceptionV3(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnTZ5vXrmLVv",
        "colab_type": "code",
        "outputId": "fe1b8d01-c2c1-44a3-805e-8a9b84fca445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoiaQ3ilBs5X",
        "colab_type": "text"
      },
      "source": [
        "Compute the loss; we want to maximize the loss during gradient ascent proces. Specifically, we maximize a weighted sum of the L2 norm of the activations of a set\n",
        "of high-level layers. Lower layers result in geometric patterns, whereas higher layers\n",
        "result in visuals observed in training data of the pretrained network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOxR0HEs79dB",
        "colab_type": "code",
        "outputId": "52c4b19d-52ee-439c-ab1e-86c284de9b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#setting up DeepDream configuration, how much the layer’s activation contributes to the loss to maximize.\n",
        "#Layer names hardcoded in inceptionV3, obtained by model.summary()\n",
        "layer_contributions = {\n",
        "    'mixed2':0.2, 'mixed3':3.,\n",
        "    'mixed4':2., 'mixed5':1.5,\n",
        "}\n",
        "\n",
        "#define the loss \n",
        "layer_dict = dict([(layer.name,layer) for layer in model.layers]) #create a dict to map layer names to layer instances\n",
        "\n",
        "loss = K.variable(0.)\n",
        "for layer_name in layer_contributions:\n",
        "  coeff = layer_contributions[layer_name]\n",
        "  activation = layer_dict[layer_name].output  #Retrieve the layer's output\n",
        "  \n",
        "  scaling = K.prod(K.cast(K.shape(activation),'float32'))\n",
        "  #Add the L2 norm of the features of a layer to the loss. Avoid border artifacts by only involving nonborder pixels in the loss\n",
        "  loss += coeff * K.sum(K.square(activation[:,2: -2, 2: -2, :])) /scaling "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IQfzGzUO211",
        "colab_type": "text"
      },
      "source": [
        "Setup Gradient ascent process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKQtgRXtO5ZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tensor to hold the generated image\n",
        "dream = model.input\n",
        "\n",
        "#compute the gradients of dream wrt loss\n",
        "grads = K.gradients(loss,dream)[0] \n",
        "\n",
        "#Normalize the gradients\n",
        "grads /= K.maximum(K.mean(K.abs(grads)),1e-7)\n",
        "\n",
        "#Setup keras function to retrieve the value of loss and gradients for an input image\n",
        "outputs = [loss,grads]\n",
        "fetch_loss_and_grads = K.function([dream], outputs)\n",
        "\n",
        "def eval_loss_and_grads(x):\n",
        "  outs = fetch_loss_and_grads([x])\n",
        "  loss_value = outs[0]\n",
        "  grad_values = outs[1] \n",
        "  return loss_value, grad_values\n",
        "\n",
        "def gradient_ascent(x, iterations, step, max_loss=None):\n",
        "  \"\"\"This function runs\n",
        "gradient ascent for a\n",
        "number of iterations\"\"\"\n",
        "  for i in range(iterations):\n",
        "    loss_value, grad_values = eval_loss_and_grads(x)\n",
        "    if max_loss is not None and loss_value > max_loss:\n",
        "      break\n",
        "    print(\"...Loss value at\",i,':', loss_value)\n",
        "    x += step*grad_values\n",
        "    \n",
        "  return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAWDgdwSkXuW",
        "colab_type": "text"
      },
      "source": [
        "### Implement the DeepDream algorithm\n",
        "\n",
        "Run gradient ascent over different successive scales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DccJfs3IkcPN",
        "colab_type": "code",
        "outputId": "0f2df53b-fad9-4585-a02b-2359e0448ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "step = 0.01     # Gradient ascent step size\n",
        "num_octave = 3  # No of scales at which to run gradient ascent\n",
        "octave_scale = 1.4 # Size ratio between scales\n",
        "iterations = 20  # No of ascent steps to run at each scale\n",
        "max_loss = 10.  #If the loss grows larger than 10, interrupt the process to avoid ugly artifacts\n",
        "base_image_path = '/content/gdrive/My Drive/Colab Notebooks/data/cc_elephant.jpg'\n",
        "img = preprocess_image(base_image_path) # Load the base image into a Numpy array\n",
        "\n",
        "original_shape = img.shape[1:3]\n",
        "successive_shapes = [original_shape]\n",
        "for i in range(1,num_octave):\n",
        "  shape = tuple([int(dim/(octave_scale**i)) for dim in original_shape])\n",
        "  successive_shapes.append(shape)\n",
        "  \n",
        "successive_shapes = successive_shapes[::-1]    #reverse list of shapes so they're in increasing order\n",
        "\n",
        "#Resizes the Numpy array of the image to the smallest scale\n",
        "original_img = np.copy(img)\n",
        "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
        "\n",
        "for shape in successive_shapes:\n",
        "  print ('Processing image shape', shape)\n",
        "  img = resize_img(img,shape)  #scale up the dream image\n",
        "  img = gradient_ascent(img, iterations=iterations, step=step, max_loss=max_loss)  #run gradient ascent altering the dream\n",
        "  \n",
        "  upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape) #scales up the smaller version of the original image: it will be pixellated\n",
        "  same_size_original = resize_img(original_img, shape)    # Computes the high-quality version of the original image at this size\n",
        "  lost_detail = same_size_original - upscaled_shrunk_original_img # The difference between the two is the detail that was lost when scaling up\n",
        "  \n",
        "  img += lost_detail  #Reinjects lost detail into the dream\n",
        "  shrunk_original_img = resize_img(original_img, shape)\n",
        "  save_img(img, fname='/content/gdrive/My Drive/Colab Notebooks/data/dream_at_scale_' + str(shape)+'.png')\n",
        "\n",
        "save_img(img, fname='/content/gdrive/My Drive/Colab Notebooks/data/final_dream.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing image shape (306, 458)\n",
            "...Loss value at 0 : 1.8070962\n",
            "...Loss value at 1 : 2.3078375\n",
            "...Loss value at 2 : 3.0242286\n",
            "...Loss value at 3 : 3.7770443\n",
            "...Loss value at 4 : 4.5572577\n",
            "...Loss value at 5 : 5.2607713\n",
            "...Loss value at 6 : 5.9627633\n",
            "...Loss value at 7 : 6.5625815\n",
            "...Loss value at 8 : 7.200746\n",
            "...Loss value at 9 : 7.76727\n",
            "...Loss value at 10 : 8.364681\n",
            "...Loss value at 11 : 8.898355\n",
            "...Loss value at 12 : 9.465099\n",
            "...Loss value at 13 : 9.956362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image shape (428, 642)\n",
            "...Loss value at 0 : 3.0523643\n",
            "...Loss value at 1 : 4.382828\n",
            "...Loss value at 2 : 5.5210733\n",
            "...Loss value at 3 : 6.488146\n",
            "...Loss value at 4 : 7.407243\n",
            "...Loss value at 5 : 8.214131\n",
            "...Loss value at 6 : 8.998534\n",
            "...Loss value at 7 : 9.683636\n",
            "Processing image shape (600, 899)\n",
            "...Loss value at 0 : 2.9750822\n",
            "...Loss value at 1 : 4.332281\n",
            "...Loss value at 2 : 5.4620795\n",
            "...Loss value at 3 : 6.464133\n",
            "...Loss value at 4 : 7.4006147\n",
            "...Loss value at 5 : 8.269527\n",
            "...Loss value at 6 : 9.078883\n",
            "...Loss value at 7 : 9.866173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbojnY7xx6vV",
        "colab_type": "text"
      },
      "source": [
        "Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8U2p9sSx5kQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_img(img, size):\n",
        "  img = np.copy(img)\n",
        "  factors = (1, float(size[0])/img.shape[1], float(size[1])/img.shape[2],1)\n",
        "  return scipy.ndimage.zoom(img, factors, order=1)\n",
        "\n",
        "def save_img(img, fname):\n",
        "  pil_img = deprocess_image(np.copy(img))\n",
        "  scipy.misc.imsave(fname, pil_img)\n",
        "  \n",
        "def preprocess_image(image_path):\n",
        "  img = image.load_img(image_path)\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = inception_v3.preprocess_input(img)\n",
        "  return img\n",
        "\n",
        "def deprocess_image(x):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    x = x.reshape((3, x.shape[2], x.shape[3]))\n",
        "    x = x.transpose((1,2,0))\n",
        "  else:\n",
        "    x = x.reshape((x.shape[1],x.shape[2],3))\n",
        "    \n",
        "  x /= 2.\n",
        "  x += 0.5\n",
        "  x *= 255.\n",
        "  x = np.clip(x,0,255).astype('uint8')\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgG5-R4_QL2h",
        "colab_type": "text"
      },
      "source": [
        "Next steps -\n",
        "\n",
        "- Explore how output changes by changing which layers we use in the loss. \n"
      ]
    }
  ]
}