{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative Adversarial Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoJzLj6_15cb",
        "colab_type": "text"
      },
      "source": [
        "Implement Deep Convolutional Generative Adversarial Networks (DCGAN) in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR9M2eI30ssM",
        "colab_type": "code",
        "outputId": "f0922078-0d3a-4558-a597-bf815eee4168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYKSC4fE337B",
        "colab_type": "code",
        "outputId": "6249d03a-016a-4abf-ef62-965945be319b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vK_ZAyE2MmO",
        "colab_type": "text"
      },
      "source": [
        "### Generator Network \n",
        "\n",
        "The Generator model turns a vector from the latent space into a candidate image. We use dropout to prevent the generator from getting stuck with generated images that look like noise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_4mgTkG2Jrc",
        "colab_type": "code",
        "outputId": "c3dccae4-89b2-440b-c173-5c8885f5ad1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "#Transform the input into a 16 x 16 128 channel feature map\n",
        "x = layers.Dense(128*16*16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16,16,128))(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "#Upsample to 32 x 32\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "#Produces a 32x32 1-channel feature map (shape of a CIFAR10 image)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "\n",
        "#Instantiates the generator model, which maps the input of shape (latent_dim) into an image of shape (32,32,3)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EortGfdHpNDB",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator Network \n",
        "\n",
        "A discriminator model takes as input a candidate image (real or synthetic) and classifies it into one of two classes: “generated image” or “real image that comes from the training set.”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIP-ANoBpT3A",
        "colab_type": "code",
        "outputId": "78445c72-de7a-4217-f3c0-2bf9bd22afc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "#One dropout layer\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "#Classification layer\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "#Instantiates the discriminator model, which turns a (32, 32, 3) input into a binary classifi-cation decision (fake/real)\n",
        "discriminator = keras.models.Model(discriminator_input,x)\n",
        "discriminator.summary()\n",
        "\n",
        "# Use gradient clipping. Use learning rate decay to stabilize training\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(lr = 0.0008, clipvalue = 1.0, decay=1e-8)\n",
        "\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urACnQp_srS7",
        "colab_type": "text"
      },
      "source": [
        "### Adversarial Network\n",
        "\n",
        "Now we setup the GAN by chaining the Generator network with the Discriminator network. The training process only updates the weights of the generator in a way that makes the discriminator more likely to predict \"real\" when looking at fake images. The weights of the discriminator are frozen i.e they are not updated during training. Otherwise we would end up training the discriminator to always predict \"real\" which is not our goal\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flw_41TFtbde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtZC9vplwx2W",
        "colab_type": "text"
      },
      "source": [
        "### Training the DCGAN \n",
        "\n",
        "For each epoch :\n",
        "\n",
        "1. Draw random points in the latent space (random noise).\n",
        "2. Generate images with `generator` using this random noise.\n",
        "3. Mix the generated images with real ones\n",
        "4. Train `discriminator` using these mixed images, with corresponding targets:\n",
        "either “real” (for the real images) or “fake” (for the generated images).\n",
        "5. Draw new random points in the latent space.\n",
        "6.Train `gan` using these random vectors, with targets that all say “these are real\n",
        "images.” This updates the weights of the generator (only, because the discriminator\n",
        "is frozen inside gan) to move them toward getting the discriminator to\n",
        "predict “these are real images” for generated images: this trains the generator\n",
        "to fool the discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLo1sbFhxVEP",
        "colab_type": "code",
        "outputId": "0ab955ab-548d-4ae8-c634-8f47d334e60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3471
        }
      },
      "source": [
        "(x_train, y_train), (_,_) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "#select only frog class images (class 6)\n",
        "x_train = x_train[y_train.flatten() == 6] \n",
        "#Normalize the data\n",
        "x_train = x_train.reshape((x_train.shape[0],) + (height, width, channels)).astype('float32')/255.\n",
        "\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "save_dir = '/content/gdrive/My Drive/Colab Notebooks/data/gan_images'\n",
        "\n",
        "start = 0\n",
        "for step in range(iterations):\n",
        "  #Sample random points in the latent space\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
        "  \n",
        "  #Decodes them to fake images\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "  stop = start + batch_size\n",
        "  real_images = x_train[start: stop]\n",
        "  \n",
        "  #combine with real images\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "  \n",
        "  #assign labels, discriminating real & fake images\n",
        "  labels = np.concatenate([np.ones((batch_size,1)), np.zeros((batch_size,1))])\n",
        "  \n",
        "  #add random noise to the labels - important trick for training\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  \n",
        "  #Train the discriminator\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  \n",
        "  #Samples random points in the latent space\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
        "  \n",
        "  #Assemble labels that say \"these are real images\"\n",
        "  misleading_targets = np.zeros((batch_size,1))\n",
        "  \n",
        "  #Train the generator (via the gan model where discriminator weights are frozen)\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "  \n",
        "  start += batch_size\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "    \n",
        "  if step%100==0: \n",
        "    gan.save_weights('gan.h5')\n",
        "    \n",
        "    print('Discriminator loss:', d_loss)\n",
        "    print('Adversarial loss:', a_loss)\n",
        "    \n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir,'generated_frog' + str(step) + '.png'))\n",
        "    \n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    img.save(os.path.join(save_dir,'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Discriminator loss: 5.2066708\n",
            "Adversarial loss: 15.942385\n",
            "Discriminator loss: 0.56745374\n",
            "Adversarial loss: 1.2648748\n",
            "Discriminator loss: 0.69516265\n",
            "Adversarial loss: 0.77763397\n",
            "Discriminator loss: 0.70561326\n",
            "Adversarial loss: 0.74772215\n",
            "Discriminator loss: 0.6780567\n",
            "Adversarial loss: 0.7215992\n",
            "Discriminator loss: 0.7011272\n",
            "Adversarial loss: 0.75191534\n",
            "Discriminator loss: 0.7009509\n",
            "Adversarial loss: 0.73629373\n",
            "Discriminator loss: 0.69797486\n",
            "Adversarial loss: 0.78167474\n",
            "Discriminator loss: 0.7018818\n",
            "Adversarial loss: 0.7335743\n",
            "Discriminator loss: 0.6980766\n",
            "Adversarial loss: 0.7550539\n",
            "Discriminator loss: 0.7686324\n",
            "Adversarial loss: 0.75139606\n",
            "Discriminator loss: 0.70752615\n",
            "Adversarial loss: 0.72950137\n",
            "Discriminator loss: 0.7012187\n",
            "Adversarial loss: 0.7445418\n",
            "Discriminator loss: 0.68844926\n",
            "Adversarial loss: 0.76178026\n",
            "Discriminator loss: 0.71396434\n",
            "Adversarial loss: 0.7601091\n",
            "Discriminator loss: 0.70142764\n",
            "Adversarial loss: 0.7624836\n",
            "Discriminator loss: 0.68898326\n",
            "Adversarial loss: 0.7501242\n",
            "Discriminator loss: 0.70386314\n",
            "Adversarial loss: 0.76227343\n",
            "Discriminator loss: 0.7076143\n",
            "Adversarial loss: 0.73320436\n",
            "Discriminator loss: 0.6898057\n",
            "Adversarial loss: 0.77601284\n",
            "Discriminator loss: 0.6901865\n",
            "Adversarial loss: 0.7540652\n",
            "Discriminator loss: 0.7198628\n",
            "Adversarial loss: 0.727718\n",
            "Discriminator loss: 0.6988207\n",
            "Adversarial loss: 1.1532791\n",
            "Discriminator loss: 0.68826354\n",
            "Adversarial loss: 0.7717556\n",
            "Discriminator loss: 0.6896343\n",
            "Adversarial loss: 0.7029699\n",
            "Discriminator loss: 0.67785597\n",
            "Adversarial loss: 0.7768728\n",
            "Discriminator loss: 0.68445724\n",
            "Adversarial loss: 0.7511307\n",
            "Discriminator loss: 0.68852437\n",
            "Adversarial loss: 0.7397514\n",
            "Discriminator loss: 0.7045501\n",
            "Adversarial loss: 0.7578218\n",
            "Discriminator loss: 0.69107217\n",
            "Adversarial loss: 0.76673615\n",
            "Discriminator loss: 0.70143336\n",
            "Adversarial loss: 0.745959\n",
            "Discriminator loss: 0.7086116\n",
            "Adversarial loss: 0.7421751\n",
            "Discriminator loss: 0.68661654\n",
            "Adversarial loss: 0.7364855\n",
            "Discriminator loss: 0.6826452\n",
            "Adversarial loss: 0.7467817\n",
            "Discriminator loss: 0.6921252\n",
            "Adversarial loss: 0.76252306\n",
            "Discriminator loss: 0.67866933\n",
            "Adversarial loss: 0.85230225\n",
            "Discriminator loss: 0.7023848\n",
            "Adversarial loss: 0.72402877\n",
            "Discriminator loss: 0.69700146\n",
            "Adversarial loss: 0.7684964\n",
            "Discriminator loss: 0.7013841\n",
            "Adversarial loss: 0.7589576\n",
            "Discriminator loss: 0.6768863\n",
            "Adversarial loss: 0.75407207\n",
            "Discriminator loss: 0.728361\n",
            "Adversarial loss: 0.7383113\n",
            "Discriminator loss: 0.69994235\n",
            "Adversarial loss: 0.7321718\n",
            "Discriminator loss: 0.6962515\n",
            "Adversarial loss: 0.7450901\n",
            "Discriminator loss: 0.7012895\n",
            "Adversarial loss: 0.72144014\n",
            "Discriminator loss: 0.6956805\n",
            "Adversarial loss: 0.7632915\n",
            "Discriminator loss: 0.6932309\n",
            "Adversarial loss: 0.7512425\n",
            "Discriminator loss: 0.68727547\n",
            "Adversarial loss: 0.72999585\n",
            "Discriminator loss: 0.6871398\n",
            "Adversarial loss: 0.7503052\n",
            "Discriminator loss: 0.6895742\n",
            "Adversarial loss: 0.72351414\n",
            "Discriminator loss: 0.70526826\n",
            "Adversarial loss: 0.7289512\n",
            "Discriminator loss: 0.7166804\n",
            "Adversarial loss: 0.8121384\n",
            "Discriminator loss: 0.7102426\n",
            "Adversarial loss: 0.7437698\n",
            "Discriminator loss: 0.7083219\n",
            "Adversarial loss: 0.76758564\n",
            "Discriminator loss: 0.690289\n",
            "Adversarial loss: 0.7468389\n",
            "Discriminator loss: 0.7399316\n",
            "Adversarial loss: 0.73337716\n",
            "Discriminator loss: 0.69680655\n",
            "Adversarial loss: 0.7636901\n",
            "Discriminator loss: 0.6900141\n",
            "Adversarial loss: 0.7222396\n",
            "Discriminator loss: 0.6924515\n",
            "Adversarial loss: 0.73645747\n",
            "Discriminator loss: 0.6970402\n",
            "Adversarial loss: 0.7502337\n",
            "Discriminator loss: 0.70629793\n",
            "Adversarial loss: 0.7487795\n",
            "Discriminator loss: 0.7410819\n",
            "Adversarial loss: 0.76412004\n",
            "Discriminator loss: 0.6804568\n",
            "Adversarial loss: 0.57189703\n",
            "Discriminator loss: 0.7020132\n",
            "Adversarial loss: 0.79831725\n",
            "Discriminator loss: 0.6809742\n",
            "Adversarial loss: 0.7338378\n",
            "Discriminator loss: 0.6898264\n",
            "Adversarial loss: 0.7569195\n",
            "Discriminator loss: 0.7061443\n",
            "Adversarial loss: 0.77877843\n",
            "Discriminator loss: 0.7087265\n",
            "Adversarial loss: 0.8092214\n",
            "Discriminator loss: 0.69081354\n",
            "Adversarial loss: 0.69227135\n",
            "Discriminator loss: 0.6729307\n",
            "Adversarial loss: 0.61468303\n",
            "Discriminator loss: 0.66422147\n",
            "Adversarial loss: 0.6096009\n",
            "Discriminator loss: 0.7016314\n",
            "Adversarial loss: 0.7534544\n",
            "Discriminator loss: 0.7068361\n",
            "Adversarial loss: 0.8601414\n",
            "Discriminator loss: 0.67207825\n",
            "Adversarial loss: 0.7534853\n",
            "Discriminator loss: 0.6630805\n",
            "Adversarial loss: 0.7785059\n",
            "Discriminator loss: 0.6748659\n",
            "Adversarial loss: 0.8879573\n",
            "Discriminator loss: 0.69779575\n",
            "Adversarial loss: 0.86465156\n",
            "Discriminator loss: 0.67691743\n",
            "Adversarial loss: 0.801857\n",
            "Discriminator loss: 0.67644936\n",
            "Adversarial loss: 0.8529496\n",
            "Discriminator loss: 0.68130296\n",
            "Adversarial loss: 1.0090849\n",
            "Discriminator loss: 0.76852125\n",
            "Adversarial loss: 0.93699855\n",
            "Discriminator loss: 0.6859039\n",
            "Adversarial loss: 1.0265975\n",
            "Discriminator loss: 0.6958801\n",
            "Adversarial loss: 0.7928761\n",
            "Discriminator loss: 0.7533391\n",
            "Adversarial loss: 1.1375065\n",
            "Discriminator loss: 0.6537414\n",
            "Adversarial loss: 0.8535814\n",
            "Discriminator loss: 0.70457214\n",
            "Adversarial loss: 0.7886752\n",
            "Discriminator loss: 0.7229618\n",
            "Adversarial loss: 1.5467556\n",
            "Discriminator loss: 0.67866975\n",
            "Adversarial loss: 0.7428136\n",
            "Discriminator loss: 0.7093747\n",
            "Adversarial loss: 0.72520864\n",
            "Discriminator loss: 0.6691331\n",
            "Adversarial loss: 0.8608335\n",
            "Discriminator loss: 0.69157696\n",
            "Adversarial loss: 0.68852407\n",
            "Discriminator loss: 0.67070377\n",
            "Adversarial loss: 0.7868648\n",
            "Discriminator loss: 0.6930657\n",
            "Adversarial loss: 0.7270504\n",
            "Discriminator loss: 0.70316017\n",
            "Adversarial loss: 0.76391745\n",
            "Discriminator loss: 0.7139111\n",
            "Adversarial loss: 0.77326787\n",
            "Discriminator loss: 0.6847409\n",
            "Adversarial loss: 0.7682574\n",
            "Discriminator loss: 0.71486336\n",
            "Adversarial loss: 0.8563455\n",
            "Discriminator loss: 0.68210304\n",
            "Adversarial loss: 0.87353706\n",
            "Discriminator loss: 0.71314937\n",
            "Adversarial loss: 0.8410576\n",
            "Discriminator loss: 0.6833588\n",
            "Adversarial loss: 0.8805866\n",
            "Discriminator loss: 0.66667646\n",
            "Adversarial loss: 0.7183989\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}